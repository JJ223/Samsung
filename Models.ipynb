{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Existem varios filtros MP/CA era giro percebermos quais são"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6776, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('budget-data/budget-data-extracted.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name            0\n",
       "quote_id                0\n",
       "description             0\n",
       "qty                    92\n",
       "unit_price            315\n",
       "filter_efficiency     228\n",
       "dimensions             83\n",
       "item_type             993\n",
       "Length                245\n",
       "Height                245\n",
       "Gutter                245\n",
       "Depth                5007\n",
       "Pockets              5007\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\2741972995.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean.drop(['qty', 'Depth','Pockets','description','item_type'], axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>quote_id</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>filter_efficiency</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>Gutter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Preditiva</td>\n",
       "      <td>17171.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>G4</td>\n",
       "      <td>625.500.50</td>\n",
       "      <td>625.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Preditiva</td>\n",
       "      <td>17171.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>F7</td>\n",
       "      <td>625.500.50</td>\n",
       "      <td>625.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Preditiva</td>\n",
       "      <td>17175.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>F7</td>\n",
       "      <td>592.490.48</td>\n",
       "      <td>592.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Preditiva</td>\n",
       "      <td>18643.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>F7</td>\n",
       "      <td>592.592.45</td>\n",
       "      <td>592.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Preditiva</td>\n",
       "      <td>18643.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>F7</td>\n",
       "      <td>287.592.45</td>\n",
       "      <td>287.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name  quote_id  unit_price filter_efficiency  dimensions  Length  \\\n",
       "0  A Preditiva   17171.0         7.5                G4  625.500.50   625.0   \n",
       "1  A Preditiva   17171.0        27.5                F7  625.500.50   625.0   \n",
       "2  A Preditiva   17175.0        28.5                F7  592.490.48   592.0   \n",
       "3  A Preditiva   18643.0        27.5                F7  592.592.45   592.0   \n",
       "4  A Preditiva   18643.0        17.5                F7  287.592.45   287.0   \n",
       "\n",
       "   Height  Gutter  \n",
       "0   500.0    50.0  \n",
       "1   500.0    50.0  \n",
       "2   490.0    48.0  \n",
       "3   592.0    45.0  \n",
       "4   592.0    45.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_clean = ['unit_price', 'filter_efficiency','Length','Height','Gutter']\n",
    "df_clean = df.dropna(subset=cols_to_clean)\n",
    "df_clean.drop(['qty', 'Depth','Pockets','description','item_type'], axis=1, inplace=True)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find individual names\n",
    "names = df_clean['company_name'].unique()\n",
    "proccessed_names = set()\n",
    "for name in names:\n",
    "    proccessed_names.add(re.sub(r'[^a-zA-Z]', '', str(name).lower()))\n",
    "\n",
    "map_names = {}\n",
    "for i, name in enumerate(proccessed_names):\n",
    "    map_names[name] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>quote_id</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>Gutter</th>\n",
       "      <th>_F7</th>\n",
       "      <th>_F8</th>\n",
       "      <th>_F9</th>\n",
       "      <th>_G2</th>\n",
       "      <th>_G3</th>\n",
       "      <th>_G4</th>\n",
       "      <th>_H13</th>\n",
       "      <th>_H14</th>\n",
       "      <th>_M5</th>\n",
       "      <th>_M6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17171.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>17171.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>17175.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>592.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>18643.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>592.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>18643.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>287.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_name  quote_id  unit_price  Length  Height  Gutter  _F7  _F8  _F9  \\\n",
       "0             0   17171.0         7.5   625.0   500.0    50.0    0    0    0   \n",
       "1             0   17171.0        27.5   625.0   500.0    50.0    1    0    0   \n",
       "2             0   17175.0        28.5   592.0   490.0    48.0    1    0    0   \n",
       "3             0   18643.0        27.5   592.0   592.0    45.0    1    0    0   \n",
       "4             0   18643.0        17.5   287.0   592.0    45.0    1    0    0   \n",
       "\n",
       "   _G2  _G3  _G4  _H13  _H14  _M5  _M6  \n",
       "0    0    0    1     0     0    0    0  \n",
       "1    0    0    0     0     0    0    0  \n",
       "2    0    0    0     0     0    0    0  \n",
       "3    0    0    0     0     0    0    0  \n",
       "4    0    0    0     0     0    0    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = df_clean.copy()\n",
    "df_model['company_name'] = df_model['company_name'].apply(lambda x: map_names.get(re.sub(r'[^a-zA-Z]', '', str(x).lower())))\n",
    "\n",
    "filterTypes = [\"G1\",\"G2\",\"G3\",\"G4\",\"M5\",\"M6\",\"F7\",\"F8\",\"F9\",\"H13\",\"H14\"]\n",
    "\n",
    "def getFilterType(x):\n",
    "    for filterType in filterTypes:\n",
    "        if filterType in x:\n",
    "            return filterType\n",
    "    return np.nan\n",
    "\n",
    "df_model['filter_efficiency'] = df_model['filter_efficiency'].apply(lambda x: getFilterType(x))\n",
    "df_model = df_model.dropna(subset=['filter_efficiency'])\n",
    "\n",
    "category_dummies = pd.get_dummies(df_model['filter_efficiency'], prefix='')\n",
    "df_model.drop(['filter_efficiency','dimensions'], axis=1, inplace=True)\n",
    "\n",
    "df_model = pd.concat([df_model, category_dummies], axis=1)\n",
    "df_model.head()\n",
    "df_model.to_csv('budget-data/budget-data-model.csv', index=False)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Neighbors Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the General Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_price</th>\n",
       "      <th>Length</th>\n",
       "      <th>Height</th>\n",
       "      <th>Gutter</th>\n",
       "      <th>_F7</th>\n",
       "      <th>_F8</th>\n",
       "      <th>_F9</th>\n",
       "      <th>_G2</th>\n",
       "      <th>_G3</th>\n",
       "      <th>_G4</th>\n",
       "      <th>_H13</th>\n",
       "      <th>_H14</th>\n",
       "      <th>_M5</th>\n",
       "      <th>_M6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.5</td>\n",
       "      <td>625.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.5</td>\n",
       "      <td>592.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.5</td>\n",
       "      <td>592.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>287.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_price  Length  Height  Gutter  _F7  _F8  _F9  _G2  _G3  _G4  _H13  \\\n",
       "0         7.5   625.0   500.0    50.0    0    0    0    0    0    1     0   \n",
       "1        27.5   625.0   500.0    50.0    1    0    0    0    0    0     0   \n",
       "2        28.5   592.0   490.0    48.0    1    0    0    0    0    0     0   \n",
       "3        27.5   592.0   592.0    45.0    1    0    0    0    0    0     0   \n",
       "4        17.5   287.0   592.0    45.0    1    0    0    0    0    0     0   \n",
       "\n",
       "   _H14  _M5  _M6  \n",
       "0     0    0    0  \n",
       "1     0    0    0  \n",
       "2     0    0    0  \n",
       "3     0    0    0  \n",
       "4     0    0    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#df_model2 = df_model.drop(['company_name'], axis=1)\n",
    "df_model2 = df_model.drop(['company_name', 'quote_id'], axis=1)\n",
    "#df_model2 = df_model.copy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_model2.drop(['unit_price'], axis=1), df_model2['unit_price'], test_size=0.2, random_state=42)\n",
    "df_model2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the top 3 filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G4 = df_model2[df_model2['_G4'] == 1]\n",
    "df_F7 = df_model2[df_model2['_F7'] == 1]\n",
    "df_M5 = df_model2[df_model2['_M5'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def get_metrics(df, model, scoring_metric):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.drop(['unit_price'], axis=1), df['unit_price'], test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(estimator=KNeighborsRegressor(),\n",
    "             param_grid={'n_neighbors': [2, 3, 5, 7, 10, 15, 17, 20],\n",
    "                         'weights': ('uniform', 'distance'),\n",
    "                         'p': [1, 2, 3]},\n",
    "            cv=5,\n",
    "            scoring=scoring_metric)\n",
    "\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(x_test)\n",
    "\n",
    "    return {\n",
    "        'scoring_metric': scoring_metric,\n",
    "        'model': model,\n",
    "        'r2': r2_score(y_test, y_pred),\n",
    "        'mse': mean_squared_error(y_test, y_pred),\n",
    "        'mae': mean_absolute_error(y_test, y_pred),\n",
    "        'rmse': math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    }\n",
    "\n",
    "\n",
    "metrics = [\"r2\", \"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"]\n",
    "\n",
    "columns = ['scoring_metric','model','r2', 'mse', 'mae', 'rmse']\n",
    "df_new = pd.DataFrame(columns=columns)\n",
    "for metric in metrics:\n",
    "    for model in [(df_model2, \"geral\"), (df_G4, \"G4\"), (df_F7, \"F7\"), (df_M5, \"M5\")]:\n",
    "        df_new = df_new.append(get_metrics(model[0], model[1], metric), ignore_index=True)\n",
    "df_new.to_csv('results/KNNeighbors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scoring_metric</th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.789150</td>\n",
       "      <td>44.327176</td>\n",
       "      <td>3.394644</td>\n",
       "      <td>6.657866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.789150</td>\n",
       "      <td>44.327176</td>\n",
       "      <td>3.394644</td>\n",
       "      <td>6.657866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.826502</td>\n",
       "      <td>36.474577</td>\n",
       "      <td>3.299196</td>\n",
       "      <td>6.039419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.817854</td>\n",
       "      <td>38.292704</td>\n",
       "      <td>3.425816</td>\n",
       "      <td>6.188110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.407117</td>\n",
       "      <td>10.591515</td>\n",
       "      <td>1.426357</td>\n",
       "      <td>3.254461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.408916</td>\n",
       "      <td>10.559390</td>\n",
       "      <td>1.421186</td>\n",
       "      <td>3.249522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.399881</td>\n",
       "      <td>10.720785</td>\n",
       "      <td>1.408649</td>\n",
       "      <td>3.274261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.407117</td>\n",
       "      <td>10.591515</td>\n",
       "      <td>1.426357</td>\n",
       "      <td>3.254461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.634940</td>\n",
       "      <td>12.387928</td>\n",
       "      <td>2.133321</td>\n",
       "      <td>3.519649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.634940</td>\n",
       "      <td>12.387928</td>\n",
       "      <td>2.133321</td>\n",
       "      <td>3.519649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.634940</td>\n",
       "      <td>12.387928</td>\n",
       "      <td>2.133321</td>\n",
       "      <td>3.519649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.634940</td>\n",
       "      <td>12.387928</td>\n",
       "      <td>2.133321</td>\n",
       "      <td>3.519649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>197.915629</td>\n",
       "      <td>3.938628</td>\n",
       "      <td>14.068249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>197.915629</td>\n",
       "      <td>3.938628</td>\n",
       "      <td>14.068249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>197.915629</td>\n",
       "      <td>3.938628</td>\n",
       "      <td>14.068249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>197.915629</td>\n",
       "      <td>3.938628</td>\n",
       "      <td>14.068249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 scoring_metric  model        r2         mse       mae  \\\n",
       "2                            r2     F7  0.789150   44.327176  3.394644   \n",
       "6        neg_mean_squared_error     F7  0.789150   44.327176  3.394644   \n",
       "10      neg_mean_absolute_error     F7  0.826502   36.474577  3.299196   \n",
       "14  neg_root_mean_squared_error     F7  0.817854   38.292704  3.425816   \n",
       "1                            r2     G4  0.407117   10.591515  1.426357   \n",
       "5        neg_mean_squared_error     G4  0.408916   10.559390  1.421186   \n",
       "9       neg_mean_absolute_error     G4  0.399881   10.720785  1.408649   \n",
       "13  neg_root_mean_squared_error     G4  0.407117   10.591515  1.426357   \n",
       "3                            r2     M5  0.634940   12.387928  2.133321   \n",
       "7        neg_mean_squared_error     M5  0.634940   12.387928  2.133321   \n",
       "11      neg_mean_absolute_error     M5  0.634940   12.387928  2.133321   \n",
       "15  neg_root_mean_squared_error     M5  0.634940   12.387928  2.133321   \n",
       "0                            r2  geral  0.353788  197.915629  3.938628   \n",
       "4        neg_mean_squared_error  geral  0.353788  197.915629  3.938628   \n",
       "8       neg_mean_absolute_error  geral  0.353788  197.915629  3.938628   \n",
       "12  neg_root_mean_squared_error  geral  0.353788  197.915629  3.938628   \n",
       "\n",
       "         rmse  \n",
       "2    6.657866  \n",
       "6    6.657866  \n",
       "10   6.039419  \n",
       "14   6.188110  \n",
       "1    3.254461  \n",
       "5    3.249522  \n",
       "9    3.274261  \n",
       "13   3.254461  \n",
       "3    3.519649  \n",
       "7    3.519649  \n",
       "11   3.519649  \n",
       "15   3.519649  \n",
       "0   14.068249  \n",
       "4   14.068249  \n",
       "8   14.068249  \n",
       "12  14.068249  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN = pd.read_csv('results/KNNeighbors.csv')\n",
    "kNN.sort_values(by=['model'], inplace=True)\n",
    "kNN.head(kNN.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def get_metrics(df1, model, scoring_metric):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df1.drop(['unit_price'], axis=1), df1['unit_price'], test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(estimator=DecisionTreeRegressor(),\n",
    "             param_grid={'criterion': ('squared_error', 'friedman_mse', 'absolute_error', 'poisson'),\n",
    "                         'splitter': ('best', 'random'),\n",
    "                         'max_features': ('auto', 'sqrt', 'log2')},\n",
    "            cv=5,\n",
    "            scoring=scoring_metric)\n",
    "\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(x_test)\n",
    "\n",
    "    return {\n",
    "        'scoring_metric': scoring_metric,\t\n",
    "        'model': model,\n",
    "        'r2': r2_score(y_test, y_pred),\n",
    "        'mse': mean_squared_error(y_test, y_pred),\n",
    "        'mae': mean_absolute_error(y_test, y_pred),\n",
    "        'rmse': math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    }\n",
    "\n",
    "metrics = [\"r2\", \"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"]\n",
    "\n",
    "columns = ['scoring_metric','model','r2', 'mse', 'mae', 'rmse']\n",
    "df_new = pd.DataFrame(columns=columns)\n",
    "for metric in metrics:\n",
    "    for model in [(df_model2, \"geral\"), (df_G4, \"G4\"), (df_F7, \"F7\"), (df_M5, \"M5\")]:\n",
    "        metrics = get_metrics(model[0], model[1], metric)\n",
    "        df_new = df_new.append(metrics, ignore_index=True)\n",
    "\n",
    "df_new.to_csv('results/decisionTree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scoring_metric</th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.885421</td>\n",
       "      <td>24.087987</td>\n",
       "      <td>2.699955</td>\n",
       "      <td>4.907951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.805983</td>\n",
       "      <td>40.788321</td>\n",
       "      <td>3.048472</td>\n",
       "      <td>6.386573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>37.977161</td>\n",
       "      <td>3.135326</td>\n",
       "      <td>6.162561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.846461</td>\n",
       "      <td>32.278741</td>\n",
       "      <td>3.029073</td>\n",
       "      <td>5.681438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2</td>\n",
       "      <td>G4</td>\n",
       "      <td>-0.043345</td>\n",
       "      <td>18.638772</td>\n",
       "      <td>1.552965</td>\n",
       "      <td>4.317264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.305595</td>\n",
       "      <td>12.405158</td>\n",
       "      <td>1.481460</td>\n",
       "      <td>3.522096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.206134</td>\n",
       "      <td>14.181963</td>\n",
       "      <td>1.587898</td>\n",
       "      <td>3.765895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>-0.303452</td>\n",
       "      <td>23.285433</td>\n",
       "      <td>1.669124</td>\n",
       "      <td>4.825498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>M5</td>\n",
       "      <td>-0.054725</td>\n",
       "      <td>35.790968</td>\n",
       "      <td>2.834845</td>\n",
       "      <td>5.982555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.378010</td>\n",
       "      <td>21.106582</td>\n",
       "      <td>2.550054</td>\n",
       "      <td>4.594190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.517317</td>\n",
       "      <td>16.379352</td>\n",
       "      <td>2.354794</td>\n",
       "      <td>4.047141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.487369</td>\n",
       "      <td>17.395587</td>\n",
       "      <td>2.530337</td>\n",
       "      <td>4.170802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>geral</td>\n",
       "      <td>-1.034905</td>\n",
       "      <td>623.231278</td>\n",
       "      <td>3.579090</td>\n",
       "      <td>24.964601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.698211</td>\n",
       "      <td>92.429002</td>\n",
       "      <td>2.692701</td>\n",
       "      <td>9.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.618813</td>\n",
       "      <td>116.746341</td>\n",
       "      <td>2.834843</td>\n",
       "      <td>10.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.668855</td>\n",
       "      <td>101.419837</td>\n",
       "      <td>2.912232</td>\n",
       "      <td>10.070742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 scoring_metric  model        r2         mse       mae  \\\n",
       "2                            r2     F7  0.885421   24.087987  2.699955   \n",
       "6        neg_mean_squared_error     F7  0.805983   40.788321  3.048472   \n",
       "10      neg_mean_absolute_error     F7  0.819355   37.977161  3.135326   \n",
       "14  neg_root_mean_squared_error     F7  0.846461   32.278741  3.029073   \n",
       "1                            r2     G4 -0.043345   18.638772  1.552965   \n",
       "5        neg_mean_squared_error     G4  0.305595   12.405158  1.481460   \n",
       "9       neg_mean_absolute_error     G4  0.206134   14.181963  1.587898   \n",
       "13  neg_root_mean_squared_error     G4 -0.303452   23.285433  1.669124   \n",
       "3                            r2     M5 -0.054725   35.790968  2.834845   \n",
       "7        neg_mean_squared_error     M5  0.378010   21.106582  2.550054   \n",
       "11      neg_mean_absolute_error     M5  0.517317   16.379352  2.354794   \n",
       "15  neg_root_mean_squared_error     M5  0.487369   17.395587  2.530337   \n",
       "0                            r2  geral -1.034905  623.231278  3.579090   \n",
       "4        neg_mean_squared_error  geral  0.698211   92.429002  2.692701   \n",
       "8       neg_mean_absolute_error  geral  0.618813  116.746341  2.834843   \n",
       "12  neg_root_mean_squared_error  geral  0.668855  101.419837  2.912232   \n",
       "\n",
       "         rmse  \n",
       "2    4.907951  \n",
       "6    6.386573  \n",
       "10   6.162561  \n",
       "14   5.681438  \n",
       "1    4.317264  \n",
       "5    3.522096  \n",
       "9    3.765895  \n",
       "13   4.825498  \n",
       "3    5.982555  \n",
       "7    4.594190  \n",
       "11   4.047141  \n",
       "15   4.170802  \n",
       "0   24.964601  \n",
       "4    9.614000  \n",
       "8   10.804922  \n",
       "12  10.070742  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = pd.read_csv('results/decisionTree.csv')\n",
    "dtree.sort_values(by=['model'], inplace=True)\n",
    "dtree.head(dtree.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.7085332  0.71168631 0.71186942\n",
      " 0.62046156 0.70122336 0.68395565        nan        nan        nan\n",
      " 0.69607957 0.70983812 0.71084575 0.6265748  0.68868854 0.67641842\n",
      "        nan        nan        nan 0.69473774 0.71019855 0.71826498\n",
      " 0.71323605 0.72090545 0.71841349        nan        nan        nan\n",
      " 0.71199758 0.71462813 0.71885465 0.69313497 0.71587217 0.71617063]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'r2', 'model': 'geral', 'r2': 0.6231866855171013, 'mse': 115.40676930789908, 'mae': 2.6671211745244006, 'rmse': 10.742754270106856}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.43027225 0.46000905 0.46099031\n",
      " 0.43162356 0.44616499 0.47745527        nan        nan        nan\n",
      " 0.43874252 0.46080943 0.47585405 0.43911832 0.44311811 0.4570082\n",
      "        nan        nan        nan 0.43872994 0.46791662 0.47993517\n",
      " 0.40366652 0.45875436 0.46685307        nan        nan        nan\n",
      " 0.44758578 0.48099734 0.47652956 0.45514754 0.47267519 0.47367525]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'r2', 'model': 'G4', 'r2': 0.5179676047173647, 'mse': 8.611237342301326, 'mae': 1.359844536423841, 'rmse': 2.9344909852138454}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.58104272 0.6029197  0.60438284\n",
      " 0.60710362 0.59925659 0.60477709        nan        nan        nan\n",
      " 0.58900783 0.57350883 0.60380897 0.547812   0.59839712 0.60012619\n",
      "        nan        nan        nan 0.45216094 0.60356733 0.616528\n",
      " 0.58275672 0.60801588 0.61360064        nan        nan        nan\n",
      " 0.61139741 0.61015628 0.60895169 0.58533313 0.60010449 0.61017683]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'r2', 'model': 'F7', 'r2': 0.8584925562701222, 'mse': 29.749236983019284, 'mae': 2.855922403560831, 'rmse': 5.4542861112174235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.42796948 0.45659988 0.44270282\n",
      " 0.37198739 0.42810861 0.43039513        nan        nan        nan\n",
      " 0.4030106  0.44257985 0.43031646 0.41403224 0.43443559 0.42311359\n",
      "        nan        nan        nan 0.34464114 0.45120016 0.45085167\n",
      " 0.44474646 0.42320588 0.44794895        nan        nan        nan\n",
      " 0.42387083 0.44861205 0.44751679 0.43199314 0.43618679 0.45459109]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'r2', 'model': 'M5', 'r2': 0.6446523957139775, 'mse': 12.058344114545804, 'mae': 2.2295992069579693, 'rmse': 3.4725126514594304}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [          nan           nan           nan -190.34754399 -183.53285866\n",
      " -183.75661086 -216.84324735 -193.62191819 -193.26654015           nan\n",
      "           nan           nan -205.26349233 -186.52161944 -190.03461424\n",
      " -197.4840714  -190.31506969 -193.02649306           nan           nan\n",
      "           nan -193.71877825 -183.9190437  -183.12301663 -185.25869148\n",
      " -185.84963952 -184.70197908           nan           nan           nan\n",
      " -190.97270759 -185.62426104 -184.0579043  -191.22718861 -185.63447428\n",
      " -184.36328272]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_mean_squared_error', 'model': 'geral', 'r2': 0.644205870039906, 'mse': 108.96921499113523, 'mae': 2.641259263854425, 'rmse': 10.43883207026223}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [         nan          nan          nan -19.01101567 -18.75700307\n",
      " -18.91262782 -21.00390496 -19.2761849  -18.65939158          nan\n",
      "          nan          nan -19.08051775 -18.24459059 -18.49942117\n",
      " -20.08292464 -18.80951326 -19.11652489          nan          nan\n",
      "          nan -19.73592037 -18.9170872  -18.78591941 -19.25296366\n",
      " -18.58126957 -18.33056293          nan          nan          nan\n",
      " -19.94034541 -18.95169783 -18.95571571 -19.65942305 -18.52870115\n",
      " -18.82071647]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_mean_squared_error', 'model': 'G4', 'r2': 0.5049421461676491, 'mse': 8.843929825548518, 'mae': 1.3842983824404709, 'rmse': 2.973874547715239}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [          nan           nan           nan -525.32434083 -520.87658667\n",
      " -521.32895587 -526.62993285 -520.18473044 -522.2683415            nan\n",
      "           nan           nan -534.25842061 -521.11757948 -520.37264991\n",
      " -520.64232622 -518.74845379 -520.33090819           nan           nan\n",
      "           nan -520.71176395 -519.10764813 -517.19869869 -556.10386696\n",
      " -517.80801267 -523.24415732           nan           nan           nan\n",
      " -526.99623686 -518.34160481 -519.580325   -551.26709434 -519.37260753\n",
      " -519.45824487]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_mean_squared_error', 'model': 'F7', 'r2': 0.8625455335545891, 'mse': 28.897175928531155, 'mae': 2.8189510385756678, 'rmse': 5.3756093541598755}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [         nan          nan          nan -38.60486722 -35.89710089\n",
      " -34.94833497 -37.51858996 -36.50800181 -35.49866403          nan\n",
      "          nan          nan -36.87273249 -35.86890904 -34.88772171\n",
      " -38.77557333 -36.19214503 -35.09685575          nan          nan\n",
      "          nan -39.14127404 -35.85374295 -34.71628961 -41.49228568\n",
      " -36.71548509 -34.99699679          nan          nan          nan\n",
      " -40.17065183 -35.38159252 -35.73213169 -37.28152622 -36.03608367\n",
      " -34.5370462 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_mean_squared_error', 'model': 'M5', 'r2': 0.6455551766076764, 'mse': 12.02770920229381, 'mae': 2.1296365979381444, 'rmse': 3.4680987878510336}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -2.82735006 -2.78537685 -2.81230334\n",
      " -2.93685873 -2.84462842 -2.85009677         nan         nan         nan\n",
      " -2.86857878 -2.82536255 -2.80048261 -2.97459392 -2.85438826 -2.84325583\n",
      "         nan         nan         nan -2.85668904 -2.74314352 -2.73299874\n",
      " -2.85057404 -2.76894252 -2.76661201         nan         nan         nan\n",
      " -2.79675129 -2.73646536 -2.72995812 -2.82715595 -2.75127247 -2.76308745]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_mean_absolute_error', 'model': 'geral', 'r2': 0.6501192035654155, 'mse': 107.15813589230974, 'mae': 2.6502648883374693, 'rmse': 10.351721397541075}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -1.6260126  -1.56502498 -1.53693008\n",
      " -1.61128511 -1.58845915 -1.55510406         nan         nan         nan\n",
      " -1.55146029 -1.5656296  -1.55317844 -1.60469302 -1.58071032 -1.54772909\n",
      "         nan         nan         nan -1.53217661 -1.54566668 -1.53675822\n",
      " -1.62105557 -1.55963256 -1.53380815         nan         nan         nan\n",
      " -1.60071567 -1.52653549 -1.52663516 -1.61296199 -1.56850312 -1.54056241]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_mean_absolute_error', 'model': 'G4', 'r2': 0.4791936573039923, 'mse': 9.303912081887418, 'mae': 1.3924291390728476, 'rmse': 3.050231480049902}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -3.77337335 -3.73189284 -3.75800836\n",
      " -3.97442986 -3.77557413 -3.75706478         nan         nan         nan\n",
      " -3.76921925 -3.7104678  -3.77015818 -3.94101849 -3.77611894 -3.75598292\n",
      "         nan         nan         nan -3.82635585 -3.60463238 -3.65979407\n",
      " -3.85526156 -3.66991117 -3.65690719         nan         nan         nan\n",
      " -3.6366442  -3.70650112 -3.6032731  -3.7762313  -3.64942478 -3.61608537]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_mean_absolute_error', 'model': 'F7', 'r2': 0.8478293715575617, 'mse': 31.990967881735905, 'mae': 2.8805332344213648, 'rmse': 5.65605585914212}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -3.59546677 -3.47446923 -3.46695217\n",
      " -3.5963269  -3.59097113 -3.54835138         nan         nan         nan\n",
      " -3.55218489 -3.46708302 -3.51375663 -3.58427565 -3.5155079  -3.51498976\n",
      "         nan         nan         nan -3.44105844 -3.45014649 -3.40230623\n",
      " -3.43472208 -3.46045688 -3.45697909         nan         nan         nan\n",
      " -3.39975844 -3.40272182 -3.43522558 -3.44123896 -3.54461351 -3.42804792]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_mean_absolute_error', 'model': 'M5', 'r2': 0.6642146420340558, 'mse': 11.394520030927833, 'mae': 2.0911649484536077, 'rmse': 3.3755769922974403}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [         nan          nan          nan -11.41331836 -11.29600815\n",
      " -11.20363193 -12.80163304 -11.81732049 -11.47458815          nan\n",
      "          nan          nan -11.45004054 -11.20375094 -11.03566962\n",
      " -11.53909051 -11.90294852 -11.58110307          nan          nan\n",
      "          nan -11.46273214 -11.13588719 -11.0767663  -11.44509796\n",
      " -11.21950514 -11.11792017          nan          nan          nan\n",
      " -11.27352296 -11.03573042 -11.06456886 -11.43815515 -11.16503837\n",
      " -11.02563298]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_root_mean_squared_error', 'model': 'geral', 'r2': 0.6419655635717112, 'mse': 109.65535457754754, 'mae': 2.639979900744417, 'rmse': 10.471645266028998}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -4.38139031 -4.13883187 -4.16215612\n",
      " -4.40617468 -4.24367676 -4.19366236         nan         nan         nan\n",
      " -4.35749483 -4.19915021 -4.16719947 -4.20331275 -4.19035653 -4.18567374\n",
      "         nan         nan         nan -4.25856454 -4.22538501 -4.09980518\n",
      " -4.29163832 -4.14590122 -4.11225228         nan         nan         nan\n",
      " -4.425553   -4.2358211  -4.18283284 -4.298203   -4.19628698 -4.13669738]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_root_mean_squared_error', 'model': 'G4', 'r2': 0.5341466278368145, 'mse': 8.322208203572021, 'mae': 1.334505380794702, 'rmse': 2.884823773399689}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [         nan          nan          nan -16.45123146 -15.92478272\n",
      " -15.76653439 -16.27225237 -15.65817752 -15.86151366          nan\n",
      "          nan          nan -15.70727011 -15.77111271 -15.73552445\n",
      " -15.66919248 -15.84702653 -15.77744428          nan          nan\n",
      "          nan -16.48415088 -15.72740936 -15.66444878 -16.22648582\n",
      " -15.61203791 -15.58141725          nan          nan          nan\n",
      " -16.72647947 -15.69668147 -15.59560918 -16.03510626 -15.7384098\n",
      " -15.55548989]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_root_mean_squared_error', 'model': 'F7', 'r2': 0.793860149897046, 'mse': 43.33696582112759, 'mae': 3.1395988130563794, 'rmse': 6.583081787516208}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\SittySoftware\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -6.07609006 -5.79694906 -5.72186764\n",
      " -6.00869171 -5.88722659 -5.7349266          nan         nan         nan\n",
      " -5.93465238 -5.68198899 -5.70909912 -5.95476826 -5.80583832 -5.79017982\n",
      "         nan         nan         nan -5.96486936 -5.67520912 -5.69486575\n",
      " -5.97657953 -5.84169603 -5.72555401         nan         nan         nan\n",
      " -5.91801384 -5.70598463 -5.75252812 -6.07568362 -5.70913039 -5.82600356]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoring_metric': 'neg_root_mean_squared_error', 'model': 'M5', 'r2': 0.6486582663607872, 'mse': 11.922409142268041, 'mae': 2.1259938144329897, 'rmse': 3.4528841773607235}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "\n",
    "def get_metrics(df1, model, scoring_metric):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df1.drop(['unit_price'], axis=1), df1['unit_price'], test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "             param_grid={'n_estimators': [10, 50, 100],\n",
    "                         'criterion': ('squared_error', 'absolute_error'),\n",
    "                         'min_samples_split': [1,2, 3],\n",
    "                         'max_features': ( 'sqrt', 'log2')},\n",
    "            cv=5,\n",
    "            scoring=scoring_metric)\n",
    "\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(x_test)\n",
    "\n",
    "    return {\n",
    "        'scoring_metric': scoring_metric,\t\n",
    "        'model': model,\n",
    "        'r2': r2_score(y_test, y_pred),\n",
    "        'mse': mean_squared_error(y_test, y_pred),\n",
    "        'mae': mean_absolute_error(y_test, y_pred),\n",
    "        'rmse': math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    }\n",
    "\n",
    "metrics = [\"r2\", \"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"]\n",
    "\n",
    "columns = ['scoring_metric','model','r2', 'mse', 'mae', 'rmse']\n",
    "df_new = pd.DataFrame(columns=columns)\n",
    "for metric in metrics:\n",
    "    for model in [(df_model2, \"geral\"), (df_G4, \"G4\"), (df_F7, \"F7\"), (df_M5, \"M5\")]:\n",
    "        metrics = get_metrics(model[0], model[1], metric)\n",
    "        print(metrics)\n",
    "        df_new = df_new.append(metrics, ignore_index=True)\n",
    "\n",
    "df_new.to_csv('results/RandomForest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scoring_metric</th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.858493</td>\n",
       "      <td>29.749237</td>\n",
       "      <td>2.855922</td>\n",
       "      <td>5.454286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.862546</td>\n",
       "      <td>28.897176</td>\n",
       "      <td>2.818951</td>\n",
       "      <td>5.375609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.847829</td>\n",
       "      <td>31.990968</td>\n",
       "      <td>2.880533</td>\n",
       "      <td>5.656056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>F7</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>43.336966</td>\n",
       "      <td>3.139599</td>\n",
       "      <td>6.583082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.517968</td>\n",
       "      <td>8.611237</td>\n",
       "      <td>1.359845</td>\n",
       "      <td>2.934491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>8.843930</td>\n",
       "      <td>1.384298</td>\n",
       "      <td>2.973875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.479194</td>\n",
       "      <td>9.303912</td>\n",
       "      <td>1.392429</td>\n",
       "      <td>3.050231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.534147</td>\n",
       "      <td>8.322208</td>\n",
       "      <td>1.334505</td>\n",
       "      <td>2.884824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.644652</td>\n",
       "      <td>12.058344</td>\n",
       "      <td>2.229599</td>\n",
       "      <td>3.472513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.645555</td>\n",
       "      <td>12.027709</td>\n",
       "      <td>2.129637</td>\n",
       "      <td>3.468099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.664215</td>\n",
       "      <td>11.394520</td>\n",
       "      <td>2.091165</td>\n",
       "      <td>3.375577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>M5</td>\n",
       "      <td>0.648658</td>\n",
       "      <td>11.922409</td>\n",
       "      <td>2.125994</td>\n",
       "      <td>3.452884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>115.406769</td>\n",
       "      <td>2.667121</td>\n",
       "      <td>10.742754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.644206</td>\n",
       "      <td>108.969215</td>\n",
       "      <td>2.641259</td>\n",
       "      <td>10.438832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.650119</td>\n",
       "      <td>107.158136</td>\n",
       "      <td>2.650265</td>\n",
       "      <td>10.351721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>geral</td>\n",
       "      <td>0.641966</td>\n",
       "      <td>109.655355</td>\n",
       "      <td>2.639980</td>\n",
       "      <td>10.471645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 scoring_metric  model        r2         mse       mae  \\\n",
       "2                            r2     F7  0.858493   29.749237  2.855922   \n",
       "6        neg_mean_squared_error     F7  0.862546   28.897176  2.818951   \n",
       "10      neg_mean_absolute_error     F7  0.847829   31.990968  2.880533   \n",
       "14  neg_root_mean_squared_error     F7  0.793860   43.336966  3.139599   \n",
       "1                            r2     G4  0.517968    8.611237  1.359845   \n",
       "5        neg_mean_squared_error     G4  0.504942    8.843930  1.384298   \n",
       "9       neg_mean_absolute_error     G4  0.479194    9.303912  1.392429   \n",
       "13  neg_root_mean_squared_error     G4  0.534147    8.322208  1.334505   \n",
       "3                            r2     M5  0.644652   12.058344  2.229599   \n",
       "7        neg_mean_squared_error     M5  0.645555   12.027709  2.129637   \n",
       "11      neg_mean_absolute_error     M5  0.664215   11.394520  2.091165   \n",
       "15  neg_root_mean_squared_error     M5  0.648658   11.922409  2.125994   \n",
       "0                            r2  geral  0.623187  115.406769  2.667121   \n",
       "4        neg_mean_squared_error  geral  0.644206  108.969215  2.641259   \n",
       "8       neg_mean_absolute_error  geral  0.650119  107.158136  2.650265   \n",
       "12  neg_root_mean_squared_error  geral  0.641966  109.655355  2.639980   \n",
       "\n",
       "         rmse  \n",
       "2    5.454286  \n",
       "6    5.375609  \n",
       "10   5.656056  \n",
       "14   6.583082  \n",
       "1    2.934491  \n",
       "5    2.973875  \n",
       "9    3.050231  \n",
       "13   2.884824  \n",
       "3    3.472513  \n",
       "7    3.468099  \n",
       "11   3.375577  \n",
       "15   3.452884  \n",
       "0   10.742754  \n",
       "4   10.438832  \n",
       "8   10.351721  \n",
       "12  10.471645  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = pd.read_csv('results/RandomForest.csv')\n",
    "rf.sort_values(by=['model'], inplace=True)\n",
    "rf.head(rf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\João\\AppData\\Local\\Temp\\ipykernel_1652\\1233751266.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>filter</th>\n",
       "      <th>scoring_metric</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>F7</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.78915</td>\n",
       "      <td>44.327176</td>\n",
       "      <td>3.394644</td>\n",
       "      <td>6.657866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.78915</td>\n",
       "      <td>44.327176</td>\n",
       "      <td>3.394644</td>\n",
       "      <td>6.657866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.826502</td>\n",
       "      <td>36.474577</td>\n",
       "      <td>3.299196</td>\n",
       "      <td>6.039419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.817854</td>\n",
       "      <td>38.292704</td>\n",
       "      <td>3.425816</td>\n",
       "      <td>6.18811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>G4</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.407117</td>\n",
       "      <td>10.591515</td>\n",
       "      <td>1.426357</td>\n",
       "      <td>3.254461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.408916</td>\n",
       "      <td>10.55939</td>\n",
       "      <td>1.421186</td>\n",
       "      <td>3.249522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.399881</td>\n",
       "      <td>10.720785</td>\n",
       "      <td>1.408649</td>\n",
       "      <td>3.274261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.407117</td>\n",
       "      <td>10.591515</td>\n",
       "      <td>1.426357</td>\n",
       "      <td>3.254461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>M5</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.63494</td>\n",
       "      <td>12.387928</td>\n",
       "      <td>2.133321</td>\n",
       "      <td>3.519649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.63494</td>\n",
       "      <td>12.387928</td>\n",
       "      <td>2.133321</td>\n",
       "      <td>3.519649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.63494</td>\n",
       "      <td>12.387928</td>\n",
       "      <td>2.133321</td>\n",
       "      <td>3.519649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.63494</td>\n",
       "      <td>12.387928</td>\n",
       "      <td>2.133321</td>\n",
       "      <td>3.519649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>geral</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>197.915629</td>\n",
       "      <td>3.938628</td>\n",
       "      <td>14.068249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>197.915629</td>\n",
       "      <td>3.938628</td>\n",
       "      <td>14.068249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>197.915629</td>\n",
       "      <td>3.938628</td>\n",
       "      <td>14.068249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNN</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.353788</td>\n",
       "      <td>197.915629</td>\n",
       "      <td>3.938628</td>\n",
       "      <td>14.068249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>F7</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.885421</td>\n",
       "      <td>24.087987</td>\n",
       "      <td>2.699955</td>\n",
       "      <td>4.907951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.805983</td>\n",
       "      <td>40.788321</td>\n",
       "      <td>3.048472</td>\n",
       "      <td>6.386573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>37.977161</td>\n",
       "      <td>3.135326</td>\n",
       "      <td>6.162561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.846461</td>\n",
       "      <td>32.278741</td>\n",
       "      <td>3.029073</td>\n",
       "      <td>5.681438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>G4</td>\n",
       "      <td>r2</td>\n",
       "      <td>-0.043345</td>\n",
       "      <td>18.638772</td>\n",
       "      <td>1.552965</td>\n",
       "      <td>4.317264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.305595</td>\n",
       "      <td>12.405158</td>\n",
       "      <td>1.48146</td>\n",
       "      <td>3.522096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.206134</td>\n",
       "      <td>14.181963</td>\n",
       "      <td>1.587898</td>\n",
       "      <td>3.765895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.303452</td>\n",
       "      <td>23.285433</td>\n",
       "      <td>1.669124</td>\n",
       "      <td>4.825498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>M5</td>\n",
       "      <td>r2</td>\n",
       "      <td>-0.054725</td>\n",
       "      <td>35.790968</td>\n",
       "      <td>2.834845</td>\n",
       "      <td>5.982555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.37801</td>\n",
       "      <td>21.106582</td>\n",
       "      <td>2.550054</td>\n",
       "      <td>4.59419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.517317</td>\n",
       "      <td>16.379352</td>\n",
       "      <td>2.354794</td>\n",
       "      <td>4.047141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.487369</td>\n",
       "      <td>17.395587</td>\n",
       "      <td>2.530337</td>\n",
       "      <td>4.170802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>geral</td>\n",
       "      <td>r2</td>\n",
       "      <td>-1.034905</td>\n",
       "      <td>623.231278</td>\n",
       "      <td>3.57909</td>\n",
       "      <td>24.964601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.698211</td>\n",
       "      <td>92.429002</td>\n",
       "      <td>2.692701</td>\n",
       "      <td>9.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.618813</td>\n",
       "      <td>116.746341</td>\n",
       "      <td>2.834843</td>\n",
       "      <td>10.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>decisionTree</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.668855</td>\n",
       "      <td>101.419837</td>\n",
       "      <td>2.912232</td>\n",
       "      <td>10.070742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>F7</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.858493</td>\n",
       "      <td>29.749237</td>\n",
       "      <td>2.855922</td>\n",
       "      <td>5.454286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.862546</td>\n",
       "      <td>28.897176</td>\n",
       "      <td>2.818951</td>\n",
       "      <td>5.375609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.847829</td>\n",
       "      <td>31.990968</td>\n",
       "      <td>2.880533</td>\n",
       "      <td>5.656056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>F7</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.79386</td>\n",
       "      <td>43.336966</td>\n",
       "      <td>3.139599</td>\n",
       "      <td>6.583082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>G4</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.517968</td>\n",
       "      <td>8.611237</td>\n",
       "      <td>1.359845</td>\n",
       "      <td>2.934491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>8.84393</td>\n",
       "      <td>1.384298</td>\n",
       "      <td>2.973875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.479194</td>\n",
       "      <td>9.303912</td>\n",
       "      <td>1.392429</td>\n",
       "      <td>3.050231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>G4</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.534147</td>\n",
       "      <td>8.322208</td>\n",
       "      <td>1.334505</td>\n",
       "      <td>2.884824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>M5</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.644652</td>\n",
       "      <td>12.058344</td>\n",
       "      <td>2.229599</td>\n",
       "      <td>3.472513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.645555</td>\n",
       "      <td>12.027709</td>\n",
       "      <td>2.129637</td>\n",
       "      <td>3.468099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.664215</td>\n",
       "      <td>11.39452</td>\n",
       "      <td>2.091165</td>\n",
       "      <td>3.375577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>M5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.648658</td>\n",
       "      <td>11.922409</td>\n",
       "      <td>2.125994</td>\n",
       "      <td>3.452884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>geral</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>115.406769</td>\n",
       "      <td>2.667121</td>\n",
       "      <td>10.742754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.644206</td>\n",
       "      <td>108.969215</td>\n",
       "      <td>2.641259</td>\n",
       "      <td>10.438832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.650119</td>\n",
       "      <td>107.158136</td>\n",
       "      <td>2.650265</td>\n",
       "      <td>10.351721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>geral</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.641966</td>\n",
       "      <td>109.655355</td>\n",
       "      <td>2.63998</td>\n",
       "      <td>10.471645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model filter               scoring_metric        r2         mse  \\\n",
       "0            KNN     F7                           r2   0.78915   44.327176   \n",
       "1            KNN     F7       neg_mean_squared_error   0.78915   44.327176   \n",
       "2            KNN     F7      neg_mean_absolute_error  0.826502   36.474577   \n",
       "3            KNN     F7  neg_root_mean_squared_error  0.817854   38.292704   \n",
       "4            KNN     G4                           r2  0.407117   10.591515   \n",
       "5            KNN     G4       neg_mean_squared_error  0.408916    10.55939   \n",
       "6            KNN     G4      neg_mean_absolute_error  0.399881   10.720785   \n",
       "7            KNN     G4  neg_root_mean_squared_error  0.407117   10.591515   \n",
       "8            KNN     M5                           r2   0.63494   12.387928   \n",
       "9            KNN     M5       neg_mean_squared_error   0.63494   12.387928   \n",
       "10           KNN     M5      neg_mean_absolute_error   0.63494   12.387928   \n",
       "11           KNN     M5  neg_root_mean_squared_error   0.63494   12.387928   \n",
       "12           KNN  geral                           r2  0.353788  197.915629   \n",
       "13           KNN  geral       neg_mean_squared_error  0.353788  197.915629   \n",
       "14           KNN  geral      neg_mean_absolute_error  0.353788  197.915629   \n",
       "15           KNN  geral  neg_root_mean_squared_error  0.353788  197.915629   \n",
       "16  decisionTree     F7                           r2  0.885421   24.087987   \n",
       "17  decisionTree     F7       neg_mean_squared_error  0.805983   40.788321   \n",
       "18  decisionTree     F7      neg_mean_absolute_error  0.819355   37.977161   \n",
       "19  decisionTree     F7  neg_root_mean_squared_error  0.846461   32.278741   \n",
       "20  decisionTree     G4                           r2 -0.043345   18.638772   \n",
       "21  decisionTree     G4       neg_mean_squared_error  0.305595   12.405158   \n",
       "22  decisionTree     G4      neg_mean_absolute_error  0.206134   14.181963   \n",
       "23  decisionTree     G4  neg_root_mean_squared_error -0.303452   23.285433   \n",
       "24  decisionTree     M5                           r2 -0.054725   35.790968   \n",
       "25  decisionTree     M5       neg_mean_squared_error   0.37801   21.106582   \n",
       "26  decisionTree     M5      neg_mean_absolute_error  0.517317   16.379352   \n",
       "27  decisionTree     M5  neg_root_mean_squared_error  0.487369   17.395587   \n",
       "28  decisionTree  geral                           r2 -1.034905  623.231278   \n",
       "29  decisionTree  geral       neg_mean_squared_error  0.698211   92.429002   \n",
       "30  decisionTree  geral      neg_mean_absolute_error  0.618813  116.746341   \n",
       "31  decisionTree  geral  neg_root_mean_squared_error  0.668855  101.419837   \n",
       "32  RandomForest     F7                           r2  0.858493   29.749237   \n",
       "33  RandomForest     F7       neg_mean_squared_error  0.862546   28.897176   \n",
       "34  RandomForest     F7      neg_mean_absolute_error  0.847829   31.990968   \n",
       "35  RandomForest     F7  neg_root_mean_squared_error   0.79386   43.336966   \n",
       "36  RandomForest     G4                           r2  0.517968    8.611237   \n",
       "37  RandomForest     G4       neg_mean_squared_error  0.504942     8.84393   \n",
       "38  RandomForest     G4      neg_mean_absolute_error  0.479194    9.303912   \n",
       "39  RandomForest     G4  neg_root_mean_squared_error  0.534147    8.322208   \n",
       "40  RandomForest     M5                           r2  0.644652   12.058344   \n",
       "41  RandomForest     M5       neg_mean_squared_error  0.645555   12.027709   \n",
       "42  RandomForest     M5      neg_mean_absolute_error  0.664215    11.39452   \n",
       "43  RandomForest     M5  neg_root_mean_squared_error  0.648658   11.922409   \n",
       "44  RandomForest  geral                           r2  0.623187  115.406769   \n",
       "45  RandomForest  geral       neg_mean_squared_error  0.644206  108.969215   \n",
       "46  RandomForest  geral      neg_mean_absolute_error  0.650119  107.158136   \n",
       "47  RandomForest  geral  neg_root_mean_squared_error  0.641966  109.655355   \n",
       "\n",
       "         mae       rmse  \n",
       "0   3.394644   6.657866  \n",
       "1   3.394644   6.657866  \n",
       "2   3.299196   6.039419  \n",
       "3   3.425816    6.18811  \n",
       "4   1.426357   3.254461  \n",
       "5   1.421186   3.249522  \n",
       "6   1.408649   3.274261  \n",
       "7   1.426357   3.254461  \n",
       "8   2.133321   3.519649  \n",
       "9   2.133321   3.519649  \n",
       "10  2.133321   3.519649  \n",
       "11  2.133321   3.519649  \n",
       "12  3.938628  14.068249  \n",
       "13  3.938628  14.068249  \n",
       "14  3.938628  14.068249  \n",
       "15  3.938628  14.068249  \n",
       "16  2.699955   4.907951  \n",
       "17  3.048472   6.386573  \n",
       "18  3.135326   6.162561  \n",
       "19  3.029073   5.681438  \n",
       "20  1.552965   4.317264  \n",
       "21   1.48146   3.522096  \n",
       "22  1.587898   3.765895  \n",
       "23  1.669124   4.825498  \n",
       "24  2.834845   5.982555  \n",
       "25  2.550054    4.59419  \n",
       "26  2.354794   4.047141  \n",
       "27  2.530337   4.170802  \n",
       "28   3.57909  24.964601  \n",
       "29  2.692701      9.614  \n",
       "30  2.834843  10.804922  \n",
       "31  2.912232  10.070742  \n",
       "32  2.855922   5.454286  \n",
       "33  2.818951   5.375609  \n",
       "34  2.880533   5.656056  \n",
       "35  3.139599   6.583082  \n",
       "36  1.359845   2.934491  \n",
       "37  1.384298   2.973875  \n",
       "38  1.392429   3.050231  \n",
       "39  1.334505   2.884824  \n",
       "40  2.229599   3.472513  \n",
       "41  2.129637   3.468099  \n",
       "42  2.091165   3.375577  \n",
       "43  2.125994   3.452884  \n",
       "44  2.667121  10.742754  \n",
       "45  2.641259  10.438832  \n",
       "46  2.650265  10.351721  \n",
       "47   2.63998  10.471645  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['model','filter','scoring_metric','r2', 'mse', 'mae', 'rmse']\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "for model in [(kNN, \"KNN\"),( dtree, \"decisionTree\"), (rf, \"RandomForest\")]:\n",
    "    for index, row in model[0].iterrows():\n",
    "        results_df = results_df.append({\n",
    "            'model': model[1],\n",
    "            'filter': row['model'],\n",
    "            'scoring_metric': row['scoring_metric'],\n",
    "            'r2': row['r2'],\n",
    "            'mse': row['mse'],\n",
    "            'mae': row['mae'],\n",
    "            'rmse': row['rmse']\n",
    "        }, ignore_index=True)\n",
    "\n",
    "results_df.to_csv('results/results.csv', index=False)\n",
    "results_df.head(results_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\João\\OneDrive\\Ambiente de Trabalho\\Uni\\5º ano\\Samsung\\Models.ipynb Cell 20\u001b[0m line \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jo%C3%A3o/OneDrive/Ambiente%20de%20Trabalho/Uni/5%C2%BA%20ano/Samsung/Models.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     plt\u001b[39m.\u001b[39mlegend()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jo%C3%A3o/OneDrive/Ambiente%20de%20Trabalho/Uni/5%C2%BA%20ano/Samsung/Models.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jo%C3%A3o/OneDrive/Ambiente%20de%20Trabalho/Uni/5%C2%BA%20ano/Samsung/Models.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plot_difference(y_test, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_difference(y_test, y_pred):\n",
    "    sorted_indices = np.argsort(y_test)\n",
    "\n",
    "    # Apply sorting to both arrays using the sorted indices\n",
    "    sorted_y_test = y_test.values[sorted_indices]\n",
    "    sorted_y_pred = y_pred[sorted_indices]\n",
    "\n",
    "    plt.figure(figsize=(50,15))\n",
    "    plt.plot(sorted_y_test, label='Real')\n",
    "    plt.plot(sorted_y_pred, label='Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_difference(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
